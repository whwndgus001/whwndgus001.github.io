## 2021-07-05


# Tokenization( 토큰화 ) 이론
텍스트 (문장, 문단, 문서)에서 어디까지가 문장이고, 무엇이 단어인지를 알려주는 것을 의미한다.

- 문장 토큰화
- 단어 토큰화
- subword 토큰화


```python
sample_text="I never thought through love we'd be. Making one as lovely as she. But isn't she lovely made from love."
```




문장 토큰화(Sentence Tokenization)


```python
tokenized_sentence = sample_text.split(". ")
tokenized_sentence
```




    ["I never thought through love we'd be",
     'Making one as lovely as she',
     "But isn't she lovely made from love."]



단어 토큰화(Word Tokenization)


```python
tokenized_word = sample_text.split()
tokenized_word
```




    ['I',
     'never',
     'thought',
     'through',
     'love',
     "we'd",
     'be.',
     'Making',
     'one',
     'as',
     'lovely',
     'as',
     'she.',
     'But',
     "isn't",
     'she',
     'lovely',
     'made',
     'from',
     'love.']



## 띄어쓰기로 영어 문장 내 단어 구분할 때의 문제점
* We're Genius!!
* We are Geinus!!
* We are Genius

위 세 문장을 각각 토큰화 하면 사람은 세 문장이 전부다 똑같은 의미라는 것을 알 수 있으나, 기계는 세 문장이 다르다고 판단.

## 해결방법 첫 번째 - 특수문자 제거를 이용해 단어 구분
* `[We, re, Genius]`
* `[We, are, Genius]`
* `[We, are, Genius]`

특수문자가 중요한 의미를 가지는 경우에도 특수문제를 삭제 하는게 맞을까?

* $12.45 -> `[12, 45]`
* Mr.So -> `[Mr, So]`
* Mrs.Kim -> `[Mrs, Kim]`
* 192.168.0.1 -> `[192, 168, 0, 1]`


## 영어 단어 토크나이저 활용하기
- TreebankWordTokenizer 패키지가 있습니다!
 - 영어 표준 토큰화 규격을 따라갑니다.
 - Penn Treebank Tokenization 규칙
- TreebankWordTokenizer의 규칙
 - 하이푼으로 구성된 단어는 하나로 유지
 - doesn't 같이 어포스트로피로 '접어'가 함께하는 단어는 따로 분리 해준다.


### 한국어의 토큰화가 어려운 이유!
1. 한국어는 교착어이다.
2. 한국어는 띄어쓰기가 잘 지켜지지 않는다.
3. 한국어는 주어생략이 가능하고, 어순도 중요하지 않다.
4. 한자어라는 특성상 하나의 음절도 다른 의미를 가질 수 있다.


### 교착어

실질적인 의미를 가지는 어간에 조사나 어미와 같은 문법 형태소가 결합하여 문법적인 기능(각각이 다른 의미를 갖는)이 부여되는 언어

### 띄어쓰기 문제
> 이렇게띄어쓰기를하지않아도일단읽을수는있잖아요
> yousugaryespleasewouldyoucomeandputitdownonme

py - hanspell 패키지 또는 ko-spacing 패키지를 이용해 문법이나 띄어쓰기 교정을 할 수 있다.

### 주어 생략 및 어순 문제
1. 나는 운동을 했어 체육관에서.
2. 나는 체육관에서 운동을 했어
3. 체육관에서 운동 했어
4. 나는 운동을 체육관에서 했어

### 한자어 특성때문에 하나의 음절이 다른 의미를 갖는 것
1. 배 라는 단어는 사람의 배, 타는 배, 먹는 배
2. 한국도 '한'은 한국 한, '국은 나라 국 이지만 각자 다른 의미로 해석될 수도 있다.(된장국 미역국 등...)

한국어 형태소 분석을 쉽게 하기 위해 konlpy 패키지 활용

!pip install knolpy

# Mecab

실무에서 가장 많이 사용되고 있는 형태소 분석
!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git
%cd Mecab-ko-for-Google-Colab
!bash install_mecab-ko_on_colab190912.sh

# Twitter,꼬꼬마,꼬모란,한나눔
속도가 Mecab이나 khaii보다 많이 느리지만 각각의 장단점이 있음.



## Cleaning(정제)과 Normalization(정규화)

### 정제란?
- 불필요한 데이터를 제거하는 것
- 텍스트 중간중간 껴있는 숫자나 특수기호를 제거하는 것
- 한국어의 경우 은,는,이,가 등의 불용어(stopwords)를 제거할 때 사용함.
- 영어의 경우는 at,is,am,the 등을 제거한다.
- 텍스트의 인코딩 문제 해결
- 길이가 짧은 단어들 제거
- 등장 빈도가 적은 단어 제거

### 정규화란?
- 문장의 복잡도를 줄여주는 과정
- 같은 의미를 가지고 있는 여러 단어를 하나로 통합하는 작업
- 영어의 경우 lemmatization
 - am, are, were, was -> be
 - has, had -> have
 - 10, 12, 100 -> num
 - ㅋ, ㅋㅋㅋㅋ, ㅋㅋㅋㅋㅋ -> ㅋㅋ
- 대소문자 통합 등

## Tokenization 실습


```python
import nltk
nltk.download('punkt') # 영어 토크나이저 활용하기
sentence = "Ain't nothin' sweeter, you want this sugar, don't ya?"
```

    [nltk_data] Downloading package punkt to /root/nltk_data...
    [nltk_data]   Unzipping tokenizers/punkt.zip.
    

## 기본 토크 나이저


```python
from nltk.tokenize import word_tokenize
print(word_tokenize(sentence))
```

    ['Ai', "n't", 'nothin', "'", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'do', "n't", 'ya', '?']
    

## WordPunkTokenizer


```python
from nltk.tokenize import WordPunctTokenizer
print(WordPunctTokenizer().tokenize(sentence))
```

    ['Ain', "'", 't', 'nothin', "'", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'don', "'", 't', 'ya', '?']
    

## TreebankWordTokenizer


```python
from nltk.tokenize import TreebankWordTokenizer
tokenizer = TreebankWordTokenizer()

print(tokenizer.tokenize(sentence))
```

    ['Ai', "n't", 'nothin', "'", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'do', "n't", 'ya', '?']
    


```python
sample_text = "I'm Iron-Man"
print(tokenizer.tokenize(sample_text))
```

    ['I', "'m", 'Iron-Man']
    

## 한글 토크나이저


```python
!pip install konlpy
```

    Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)
    Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)
    Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)
    Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)
    Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.1.2)
    Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.4)
    Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)
    Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)
    Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)
    Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)
    Requirement already satisfied: typing-extensions; python_version < "3.8" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)
    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)
    Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)
    Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)
    Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == "socks" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)
    Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)
    


```python
!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git
%cd Mecab-ko-for-Google-Colab
!bash install_mecab-ko_on_colab190912.sh
```

    Cloning into 'Mecab-ko-for-Google-Colab'...
    remote: Enumerating objects: 72, done.[K
    remote: Counting objects: 100% (72/72), done.[K
    remote: Compressing objects: 100% (67/67), done.[K
    remote: Total 72 (delta 31), reused 20 (delta 5), pack-reused 0[K
    Unpacking objects: 100% (72/72), done.
    /content/Mecab-ko-for-Google-Colab
    Installing konlpy.....
    Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)
    Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.1.2)
    Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)
    Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)
    Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)
    Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.4)
    Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)
    Requirement already satisfied: typing-extensions; python_version < "3.8" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)
    Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)
    Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)
    Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)
    Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)
    Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)
    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)
    Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == "socks" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)
    Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)
    Done
    Installing mecab-0.996-ko-0.9.2.tar.gz.....
    Downloading mecab-0.996-ko-0.9.2.tar.gz.......
    from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
    --2020-11-10 08:36:41--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
    Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c2:513, 2406:da00:ff00::22e9:9f55, ...
    Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.
    HTTP request sent, awaiting response... 302 Found
    Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=GRuVOO7jH9HD1Z65e5oeHJZtRIM%3D&Expires=1604998553&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]
    --2020-11-10 08:36:42--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=GRuVOO7jH9HD1Z65e5oeHJZtRIM%3D&Expires=1604998553&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None
    Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.244.116
    Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.244.116|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 1414979 (1.3M) [application/x-tar]
    Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’
    
    mecab-0.996-ko-0.9. 100%[===================>]   1.35M  1.19MB/s    in 1.1s    
    
    2020-11-10 08:36:44 (1.19 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]
    
    Done
    Unpacking mecab-0.996-ko-0.9.2.tar.gz.......
    Done
    Change Directory to mecab-0.996-ko-0.9.2.......
    installing mecab-0.996-ko-0.9.2.tar.gz........
    configure
    make
    make check
    make install
    ldconfig
    Done
    Change Directory to /content
    Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......
    from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz
    --2020-11-10 08:38:22--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz
    Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db, 2406:da00:ff00::22c3:9b0a, ...
    Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.
    HTTP request sent, awaiting response... 302 Found
    Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=aWBjU1kNrFMDbplow%2BcMS9ZMwmc%3D&Expires=1604999303&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]
    --2020-11-10 08:38:23--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=aWBjU1kNrFMDbplow%2BcMS9ZMwmc%3D&Expires=1604999303&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None
    Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.141.196
    Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.141.196|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 49775061 (47M) [application/x-tar]
    Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’
    
    mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  13.1MB/s    in 4.2s    
    
    2020-11-10 08:38:28 (11.4 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]
    
    Done
    Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......
    Done
    Change Directory to mecab-ko-dic-2.1.1-20180720
    Done
    installing........
    configure
    make
    make install
    apt-get update
    apt-get upgrade
    apt install curl
    apt install git
    bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)
    Done
    Successfully Installed
    Now you can use Mecab
    from konlpy.tag import Mecab
    mecab = Mecab()
    사용자 사전 추가 방법 : https://bit.ly/3k0ZH53
    


```python
from konlpy.tag import Hannanum # 한나눔
from konlpy.tag import Kkma # 꼬꼬마
from konlpy.tag import Komoran # 코모란
from konlpy.tag import Okt # 트위터
# from konlpy.tag import Mecab # 메캡

hannanum = Hannanum()
kkma = Kkma()
komoran = Komoran()
okt = Okt()
# mecab = Mecab()

sentence = "좋으니 그 사람 솔직히 견디기 버거워"
```

## 트위터( Okt )


```python
print(okt.nouns(sentence)) # 명사만 추출
print(okt.morphs(sentence)) # 각 형태소 별로 토큰화
print(okt.pos(sentence))  # 각 형태소 토큰 및 형태소 종류를 튜플로 표시
```

    ['그', '사람']
    ['좋으니', '그', '사람', '솔직히', '견디기', '버거워']
    [('좋으니', 'Adjective'), ('그', 'Noun'), ('사람', 'Noun'), ('솔직히', 'Adjective'), ('견디기', 'Verb'), ('버거워', 'Adjective')]
    


```python

```

## 꼬꼬마( Kkma )


```python
print(kkma.nouns(sentence)) # 명사만 추출
print(kkma.morphs(sentence)) # 각 형태소 별로 토큰화
print(kkma.pos(sentence))  # 각 형태소 토큰 및 형태소 종류를 튜플로 표시
```

    ['사람']
    ['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버겁', '어']
    [('좋', 'VA'), ('으니', 'ECD'), ('그', 'MDT'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버겁', 'VA'), ('어', 'ECS')]
    

## 코모란( Komoran )


```python
print(komoran.nouns(sentence)) # 명사만 추출
print(komoran.morphs(sentence)) # 각 형태소 별로 토큰화
print(komoran.pos(sentence))  # 각 형태소 토큰 및 형태소 종류를 튜플로 표시
```

    ['사람']
    ['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']
    [('좋', 'VA'), ('으니', 'EC'), ('그', 'MM'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버거워', 'NA')]
    

## 한나눔( Hannanum )


```python
print(hannanum.nouns(sentence)) # 명사만 추출
print(hannanum.morphs(sentence)) # 각 형태소 별로 토큰화
print(hannanum.pos(sentence))  # 각 형태소 토큰 및 형태소 종류를 튜플로 표시
```

    ['사람', '버거워']
    ['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']
    [('좋', 'P'), ('으니', 'E'), ('그', 'M'), ('사람', 'N'), ('솔직히', 'M'), ('견디', 'P'), ('기', 'E'), ('버거워', 'N')]
    

## 메캅( Mecab)


```python
print(mecab.nouns(sentence)) # 명사만 추출
print(mecab.morphs(sentence)) # 각 형태소 별로 토큰화
print(mecab.pos(sentence))  # 각 형태소 토큰 및 형태소 종류를 튜플로 표시
```


    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    <ipython-input-20-9c503f0ec311> in <module>()
    ----> 1 print(mecab.nouns(sentence)) # 명사만 추출
          2 print(mecab.morphs(sentence)) # 각 형태소 별로 토큰화
          3 print(mecab.pos(sentence))  # 각 형태소 토큰 및 형태소 종류를 튜플로 표시
    

    NameError: name 'mecab' is not defined


## 문장 토크나이징

단순히 물음표, 온점(.), 느낌표 등으로 문장을 잘라내면 문장 토크나이징일까?

`니 아이피가 192.168.56.51 맞니?`

`looking for Ph.D.Students`
등과 같이 온점이나 기호가 의미를 갖는 경우가 많다.


```python
text = "Since I'm actively looking for Ph.D. students. I get the same question a dozen times every year."
```


```python
from nltk.tokenize import sent_tokenize
print(sent_tokenize(text))
```

    ["Since I'm actively looking for Ph.D. students.", 'I get the same question a dozen times every year.']
    


```python
text = "My IP Address is 192.168.56.51, Hello world!"
print(sent_tokenize(text))
```

    ['My IP Address is 192.168.56.51, Hello world!']
    


```python
!pip install kss
```

    Collecting kss
      Downloading https://files.pythonhosted.org/packages/fc/bb/4772901b3b934ac204f32a0bd6fc0567871d8378f9bbc7dd5fd5e16c6ee7/kss-1.3.1.tar.gz
    Building wheels for collected packages: kss
      Building wheel for kss (setup.py) ... [?25l[?25hdone
      Created wheel for kss: filename=kss-1.3.1-cp36-cp36m-linux_x86_64.whl size=251551 sha256=83b274245744d597014e87614c48b59bc0152cf676b4f20f64af8c4e9cca352d
      Stored in directory: /root/.cache/pip/wheels/8b/98/d1/53f75f89925cd95779824778725ee3fa36e7aa55ed26ad54a8
    Successfully built kss
    Installing collected packages: kss
    Successfully installed kss-1.3.1
    


```python
import kss
text = "제 아이피는 192.168.56.21 이에요. 자연어 처리가 재미있나요?ㅋㅋ 딥러닝 들어가면 뚝배기가 아파와요"
print(kss.split_sentences(text))
```

    ['제 아이피는 192.168.56.21 이에요.', '자연어 처리가 재미있나요?ㅋㅋ', '딥러닝 들어가면 뚝배기가 아파와요']
    

## 띄어쓰기 및 맞춤법 정리하기

### KoSpacing
'''
!pip install git+https://github.com/haven-jeon/PyKoSpacing.git
'''
### hanspell
'''
!pip install git+https://github.com/ssut/py-hanspell.git
'''


```python
!pip install git+https://github.com/haven-jeon/PyKoSpacing.git
```

    Collecting git+https://github.com/haven-jeon/PyKoSpacing.git
      Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-1bu5hr4l
      Running command git clone -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-1bu5hr4l
    Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.3.0)
    Requirement already satisfied: keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.4.3)
    Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.10.0)
    Collecting argparse>=1.4.0
      Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl
    Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.15.0)
    Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.3.3)
    Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.18.5)
    Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (2.3.0)
    Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (3.3.0)
    Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.1.0)
    Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.12.1)
    Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.10.0)
    Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.1.2)
    Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.6.3)
    Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.2.0)
    Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.4.1)
    Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (2.3.0)
    Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.33.2)
    Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (3.12.4)
    Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.35.1)
    Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.4.3->pykospacing==0.3) (3.13)
    Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (50.3.2)
    Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.7.0)
    Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.23.0)
    Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.4.2)
    Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.3.3)
    Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.17.2)
    Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.0.1)
    Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.0.4)
    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.24.3)
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2020.6.20)
    Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.10)
    Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.3.0)
    Requirement already satisfied: importlib-metadata; python_version < "3.8" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.0.0)
    Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.2.8)
    Requirement already satisfied: rsa<5,>=3.1.4; python_version >= "3" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (4.6)
    Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (4.1.1)
    Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.1.0)
    Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < "3.8"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.4.0)
    Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.4.8)
    Building wheels for collected packages: pykospacing
      Building wheel for pykospacing (setup.py) ... [?25l[?25hdone
      Created wheel for pykospacing: filename=pykospacing-0.3-cp36-none-any.whl size=2255638 sha256=78d79e8aa07728ed4e8869da447a7e92e7be457ffd6dc1fab3dcb21cb1ca725f
      Stored in directory: /tmp/pip-ephem-wheel-cache-pfmq57s5/wheels/4d/45/58/e26cb2b7f6a063d234158c6fd1e5700f6e15b99d67154340ba
    Successfully built pykospacing
    Installing collected packages: argparse, pykospacing
    Successfully installed argparse-1.4.0 pykospacing-0.3
    




```python
!pip install git+https://github.com/ssut/py-hanspell.git
```

    Collecting git+https://github.com/ssut/py-hanspell.git
      Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-sl295ns_
      Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-sl295ns_
    Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from py-hanspell==1.1) (2.23.0)
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (2020.6.20)
    Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (3.0.4)
    Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (2.10)
    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (1.24.3)
    Building wheels for collected packages: py-hanspell
      Building wheel for py-hanspell (setup.py) ... [?25l[?25hdone
      Created wheel for py-hanspell: filename=py_hanspell-1.1-cp36-none-any.whl size=4854 sha256=31b8cdaeb3be9c3e952ae44ab5524c59e5480e268f3d05e60e3df66eed6f88e6
      Stored in directory: /tmp/pip-ephem-wheel-cache-hdk1_2j1/wheels/0a/25/d1/e5e96476dbb1c318cc26c992dd493394fe42b0c204b3e65588
    Successfully built py-hanspell
    Installing collected packages: py-hanspell
    Successfully installed py-hanspell-1.1
    


```python
from hanspell import spell_checker
from pykospacing import spacing
```


```python
# KoSpacing을 이용한 띄어쓰기 정리
text = "4번놀고있지.4번은팀워크가없어.4번은개인주의야.4번은혼자밖에생각하지않아."
spacing_text = spacing(text)
print(spacing_text)
```

    4번 놀고 있지.4번은 팀워크가 없어.4번은 개인주의야.4번은 혼자 밖에 생각하지 않아.
    


```python
# hanspell을 이용한 문법 정리
text = "4번놀고있지.4번은팀워크가없어.4번은개인주의야.4번은혼자밖에생각하지않아."
hanspell_text = spell_checker.check(text).checked
print(hanspell_text)
```

    4번 놀고 있지. 4번은 팀워크가 없어. 4번은 개인주의야. 4번은 혼자밖에 생각하지 않아.
    

## 텍스트 정규화
문장의 복잡도를 낮추는 과정. 복잡도가 낮아지기 때문에 처리할 단어가 줄어든다.

### 영어 정규화 - Stemming
어간(stem)을 추출하는 과정 - 영어에서는 사전에 없는 단어가 나오는 경우가 종종 있다.

* `Serialize -> Serial`
* `Allowance -> allow`
* `Medical -> medic`
* `This -> thi


```python
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize
porter_stemmer = PorterStemmer()
```


```python
text = "This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things—names and heights and soundings—with the single exception of the red crosses and the written notes."
words = word_tokenize(text)
print(words)
```

    ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', "'s", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things—names', 'and', 'heights', 'and', 'soundings—with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']
    


```python
print([porter_stemmer.stem(w) for w in words])
```

    ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', "'s", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'things—nam', 'and', 'height', 'and', 'soundings—with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']
    


```python
words = ['Serialize', 'Allowance', "Medical", 'This']
print([porter_stemmer.stem(w) for w in words])
```

    ['serial', 'allow', 'medic', 'thi']
    

## 영어 정규화 - Lemmatization
표제어 추출- 복수를 단수로, am, is -> be로 바꿔주는 역할


```python
nltk.download('wordnet')
```

    [nltk_data] Downloading package wordnet to /root/nltk_data...
    [nltk_data]   Unzipping corpora/wordnet.zip.
    




    True




```python
from nltk.stem import WordNetLemmatizer
wordnet_lemmatizer = WordNetLemmatizer()

words=['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']
print([wordnet_lemmatizer.lemmatize(w) for w in words])
```

    ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']
    

## 한국어 정규화 - Stemming, Normalization
형태소 분리기인 Okt에는 특정 단어의 어간(stem)및 정규화 기능이 있다.


```python
!pip install konlpy
```

    Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)
    Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)
    Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)
    Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.4)
    Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)
    Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)
    Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.1.2)
    Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)
    Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)
    Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)
    Requirement already satisfied: typing-extensions; python_version < "3.8" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)
    Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)
    Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)
    Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)
    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)
    Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == "socks" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)
    


```python
okt = Okt()

text = "4번 놀고 있지. 4번은 팀워크가 없어. 4번은 개인주의야. 4번은 혼자밖에 생각하지 않아."
print(okt.morphs(text)) # 형태소 분리 후 배열로 리턴
print(okt.morphs(text, stem = True))
```

    ['4', '번', '놀고', '있지', '.', '4', '번은', '팀워크', '가', '없어', '.', '4', '번은', '개인주의', '야', '.', '4', '번은', '혼자', '밖에', '생각', '하지', '않아', '.']
    ['4', '번', '놀다', '있다', '.', '4', '번은', '팀워크', '가', '없다', '.', '4', '번은', '개인주의', '야', '.', '4', '번은', '혼자', '밖에', '생각', '하다', '않다', '.']
    


```python
print(okt.pos(text))
print(okt.pos(text, stem= True))
```

    [('4', 'Number'), ('번', 'Noun'), ('놀고', 'Verb'), ('있지', 'Adjective'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('팀워크', 'Noun'), ('가', 'Josa'), ('없어', 'Adjective'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('개인주의', 'Noun'), ('야', 'Josa'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('혼자', 'Noun'), ('밖에', 'Josa'), ('생각', 'Noun'), ('하지', 'Verb'), ('않아', 'Verb'), ('.', 'Punctuation')]
    [('4', 'Number'), ('번', 'Noun'), ('놀다', 'Verb'), ('있다', 'Adjective'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('팀워크', 'Noun'), ('가', 'Josa'), ('없다', 'Adjective'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('개인주의', 'Noun'), ('야', 'Josa'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('혼자', 'Noun'), ('밖에', 'Josa'), ('생각', 'Noun'), ('하다', 'Verb'), ('않다', 'Verb'), ('.', 'Punctuation')]
    


```python
# 하지마랔ㅋㅋㅋㅋ -> 하지마라 ㅋㅋㅋㅋ
text = "웃기는 소리하지마랔ㅋㅋㅋㅋ"

print(okt.morphs(text))
print(okt.morphs(text, norm = True))
print(okt.pos(text))
print(okt.pos(text, norm = True))
```

    ['웃기는', '소리', '하지마', '랔', 'ㅋㅋㅋㅋ']
    ['웃기는', '소리', '하지마라', 'ㅋㅋㅋ']
    [('웃기는', 'Verb'), ('소리', 'Noun'), ('하지마', 'Verb'), ('랔', 'Noun'), ('ㅋㅋㅋㅋ', 'KoreanParticle')]
    [('웃기는', 'Verb'), ('소리', 'Noun'), ('하지마라', 'Verb'), ('ㅋㅋㅋ', 'KoreanParticle')]
    


```python
print(okt.pos(text, norm = True, stem = True))
```

    [('웃기다', 'Verb'), ('소리', 'Noun'), ('하다', 'Verb'), ('ㅋㅋㅋ', 'KoreanParticle')]
    

## 이모티콘이나 의미없이 반복되는 문자도 정제하기

* ex) ㅋㅋ, ㅋㅋㅋㅋ, ㅋㅋㅋㅋㅋㅋ
* ex) 와하하하핫 와하하핫 와하하하하하핫

```
!pip install soynlp
```


```python
!pip install soynlp
```

    Collecting soynlp
    [?25l  Downloading https://files.pythonhosted.org/packages/7e/50/6913dc52a86a6b189419e59f9eef1b8d599cffb6f44f7bb91854165fc603/soynlp-0.0.493-py3-none-any.whl (416kB)
    [K     |████████████████████████████████| 419kB 4.5MB/s 
    [?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from soynlp) (0.22.2.post1)
    Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from soynlp) (1.18.5)
    Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.6/dist-packages (from soynlp) (5.4.8)
    Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from soynlp) (1.4.1)
    Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->soynlp) (0.17.0)
    Installing collected packages: soynlp
    Successfully installed soynlp-0.0.493
    


```python
from soynlp.normalizer import emoticon_normalize

print(emoticon_normalize("앜ㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠ", num_repeats = 2))
print(emoticon_normalize("앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠ", num_repeats = 2))
print(emoticon_normalize("앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ", num_repeats = 2))
print(emoticon_normalize("앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ", num_repeats = 2))
```

    아ㅋㅋ영화존잼쓰ㅠㅠ
    아ㅋㅋ영화존잼쓰ㅠㅠ
    아ㅋㅋ영화존잼쓰ㅠㅠ
    아ㅋㅋ영화존잼쓰ㅠㅠ
    


```python
from soynlp.normalizer import repeat_normalize
print(repeat_normalize("와하하핫", num_repeats = 2))
print(repeat_normalize("와하하하하핫", num_repeats = 2))
print(repeat_normalize("와하하하하하하핫", num_repeats = 2))
```

    와하하핫
    와하하핫
    와하하핫
    

## 텍스트 정제

### 정규식을 이용한 정제
특수기호나 의미없는 공백등을 정규식을 활용해서 제거하는 작업

### 불용어(stopwords) 정제
빈도수가 낮거나, 의미없는 단어를 문장에서 제거하는 작업


```python
import re

eng_sent = "\n\n\n\n\n\n\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\nof steam!\n\n\n\n\n\n\n\nJim,\n\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\ndenial about the faith you need to get by.  Oh well, just pretend that it will\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\nalt.atheist.hard, you won't be bummin' so much?\n\n\n\n\n\n\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \n—\nBake Timmons, III"
print(eng_sent)
```

    
    
    
    
    
    
    
    Yeah, do you expect people to read the FAQ, etc. and actually accept hard
    atheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out
    of steam!
    
    
    
    
    
    
    
    Jim,
    
    Sorry I can't pity you, Jim.  And I'm sorry that you have these feelings of
    denial about the faith you need to get by.  Oh well, just pretend that it will
    all end happily ever after anyway.  Maybe if you start a new newsgroup,
    alt.atheist.hard, you won't be bummin' so much?
    
    
    
    
    
    
    Bye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) 
    —
    Bake Timmons, III
    

영어 알파벳만 뽑아내는 정규식 `[a-zA-z]`


```python
eng_sent = re.sub("[^a-zA-Z]", " ",eng_sent)
eng_sent
```




    '       Yeah  do you expect people to read the FAQ  etc  and actually accept hard atheism   No  you need a little leap of faith  Jimmy   Your logic runs out of steam         Jim   Sorry I can t pity you  Jim   And I m sorry that you have these feelings of denial about the faith you need to get by   Oh well  just pretend that it will all end happily ever after anyway   Maybe if you start a new newsgroup  alt atheist hard  you won t be bummin  so much        Bye Bye  Big Jim   Don t forget your Flintstone s Chewables         Bake Timmons  III'




```python
aaa = 'a b c'
aaa.split(' ')
```




    ['a', 'b', 'c']




```python
aaa = 'a  b c'
aaa.split(' ')
```




    ['a', '', 'b', 'c']




```python
aaa ='a  b c'
aaa.split()
```




    ['a', 'b', 'c']




```python
# 4글자 이상인 단어만 추출해서 새롭게 문장 만들기
eng_sent = ' '.join([w for w in eng_sent.split() if len(w) > 3])
eng_sent
```




    'Yeah expect people read actually accept hard atheism need little leap faith Jimmy Your logic runs steam Sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway Maybe start newsgroup atheist hard bummin much forget your Flintstone Chewables Bake Timmons'



## 한국어 정규 표현식 정제
한국어 문장에서 한글만 추출하는 정규식 표현 `[ㄱ-ㅎㅏ-ㅣ가-힣]`


```python
kor_sent = "와 이런 것도 영화라고....ㅋㅋㅋ 차라리 뮤직비디오를 만드는 게 나을 뻔!!"
kor_sent
```




    '와 이런 것도 영화라고....ㅋㅋㅋ 차라리 뮤직비디오를 만드는 게 나을 뻔!!'




```python
kor_sent = re.sub("[^ㄱ-ㅎㅏ-ㅣ가-힣]", " ", kor_sent)
kor_sent
```




    '와 이런 것도 영화라고    ㅋㅋㅋ 차라리 뮤직비디오를 만드는 게 나을 뻔  '




```python
kor_sent = re.sub("[  ]{2,}", " ",kor_sent)
kor_sent
```




    '와 이런 것도 영화라고 ㅋㅋㅋ 차라리 뮤직비디오를 만드는 게 나을 뻔 '



## Stopwords 설정하기
영어의 I, my, me, over, the


```python
nltk.download('stopwords')
```

    [nltk_data] Downloading package stopwords to /root/nltk_data...
    [nltk_data]   Unzipping corpora/stopwords.zip.
    




    True




```python
from nltk.corpus import stopwords
print(stopwords.words("english"))
```

    ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself', 'it', "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn', "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't"]
    


```python
example = "Family in not an importanta thing. It's everything"
stop_words = set(stopwords.words('english')) # 영어 불용어 집합 만들기

word_tokens = word_tokenize(example) # 먼저 문장에 대한 단어 토큰화 수행

result = []

for w in word_tokens:
  if w not in stop_words: #불용어 처리 수행
    result.append(w)
print("원문 : ", word_tokens)
print("불용어 제거 후 : ", result)
```

    원문 :  ['Family', 'in', 'not', 'an', 'importanta', 'thing', '.', 'It', "'s", 'everything']
    불용어 제거 후 :  ['Family', 'importanta', 'thing', '.', 'It', "'s", 'everything']
    


```python
example = "와 이런 것도 영화라고 차라리 뮤직비디오를 만드는 게 나을 뻔"
word_tokens = okt.morphs(example)
print(word_tokens)
```

    ['와', '이런', '것', '도', '영화', '라고', '차라리', '뮤직비디오', '를', '만드는', '게', '나을', '뻔']
    


```python
# 개발자가 임의로 불용어를 선정할 수 있다.
# 일반적으로 조사나 접속사들이 불용어로 선정된다.
stop_words = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다', '것']
```


```python
result = [word for word in word_tokens if not word in stop_words]

print("원문 :", word_tokens)
print("불용어 제거 후: ", result)
```

    원문 : ['와', '이런', '것', '도', '영화', '라고', '차라리', '뮤직비디오', '를', '만드는', '게', '나을', '뻔']
    불용어 제거 후:  ['이런', '영화', '라고', '차라리', '뮤직비디오', '만드는', '게', '나을', '뻔']
    


```python

```
