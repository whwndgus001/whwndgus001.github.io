## Integer Encoding
ë¬¸ì¥ì„ êµ¬ì„±í•˜ëŠ” ë‹¨ì–´ë“¤ì— ëŒ€í•´ ìˆ«ì ë¶€ì—¬í•˜ê¸° ë³´í†µ ABCìˆœ ë˜ëŠ” ë¹ˆë„ê°€ ë†’ì€ìˆœìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.


```python
import nltk
nltk.download('punkt')
```

    [nltk_data] Downloading package punkt to /root/nltk_data...
    [nltk_data]   Unzipping tokenizers/punkt.zip.
    




    True




```python
from nltk.tokenize import sent_tokenize

text = """Isn't she lovely.
Isn't she wonderful.
Isn't she precious.
Less than one minute old.
I never thought through love we'd be.
Making one as lovely as she.
But isn't she lovely made from love.
Isn't she pretty.
Truly the angel's best.
Boy, I'm so happy.
We have been heaven blessed.
I can't believe what God has done.
Through us he's given life to one.
But isn't she lovely made from love.
Isn't she lovely.
Life and love are the same.
Life is Aisha.
The meaning of her name.
Londie, it could have not been done.
Without you who conceived the one.
That's so very lovely made from love."""

text = sent_tokenize(text)
print(text)
```

    ["Isn't she lovely.", "Isn't she wonderful.", "Isn't she precious.", 'Less than one minute old.', "I never thought through love we'd be.", 'Making one as lovely as she.', "But isn't she lovely made from love.", "Isn't she pretty.", "Truly the angel's best.", "Boy, I'm so happy.", 'We have been heaven blessed.', "I can't believe what God has done.", "Through us he's given life to one.", "But isn't she lovely made from love.", "Isn't she lovely.", 'Life and love are the same.', 'Life is Aisha.', 'The meaning of her name.', 'Londie, it could have not been done.', 'Without you who conceived the one.', "That's so very lovely made from love."]
    

## Word Tokenization


```python
nltk.download('stopwords')
```

    [nltk_data] Downloading package stopwords to /root/nltk_data...
    [nltk_data]   Unzipping corpora/stopwords.zip.
    




    True




```python
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

sentences = []
stop_words = set(stopwords.words('english')) # NLTK ë¶ˆìš©ì–´

# ë¬¸ì¥ë³„ ë‹¨ì–´ í† í°í™”
for i in text:
  # print(i)
  sentence = word_tokenize(i) # ë‹¨ì–´ í† í°í™”
  result = []

  # ì •ì œ ì‘ì—… ìˆ˜í–‰
  for word in sentence:
    word = word.lower() # ëª¨ë“  ë‹¨ì–´ì˜ ì•ŒíŒŒë²³ì„ ì†Œë¬¸ìë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤.

    # ë¶ˆìš©ì–´ ì œê±°í•˜ê¸°
    if word not in stop_words:
      if len(word) > 2: # ë‹¨ì–´ì˜ ê¸¸ì´ê°€ 2ì´í•˜ì¸ ê²½ìš°ì—ë„ ë‹¨ì–´ë¥¼ ì œê±°
        result.append(word)

  sentences.append(result)
  
print(sentences)

```

    [["n't", 'lovely'], ["n't", 'wonderful'], ["n't", 'precious'], ['less', 'one', 'minute', 'old'], ['never', 'thought', 'love'], ['making', 'one', 'lovely'], ["n't", 'lovely', 'made', 'love'], ["n't", 'pretty'], ['truly', 'angel', 'best'], ['boy', 'happy'], ['heaven', 'blessed'], ["n't", 'believe', 'god', 'done'], ['given', 'life', 'one'], ["n't", 'lovely', 'made', 'love'], ["n't", 'lovely'], ['life', 'love'], ['life', 'aisha'], ['meaning', 'name'], ['londie', 'could', 'done'], ['without', 'conceived', 'one'], ['lovely', 'made', 'love']]
    

## ë‹¨ì–´ ì§‘í•© ë§Œë“¤ê¸°( Python )


```python
from collections import Counter # ë°°ì—´ì— ìˆëŠ” ì›ì†Œì˜ ê°œìˆ˜ë¥¼ ì„¸ì„œ ë”•ì…”ë„ˆë¦¬í™” í•´ì¤€ë‹¤.

# 2ì°¨ì› ë°°ì—´ í˜•ì‹ì˜ ë‹¨ì–´ ì§‘í•©ì„ 1ì°¨ì›ìœ¼ë¡œ í’€ì–´ì¤€ë‹¤.
words = sum(sentences, [])
print(words)
```

    ["n't", 'lovely', "n't", 'wonderful', "n't", 'precious', 'less', 'one', 'minute', 'old', 'never', 'thought', 'love', 'making', 'one', 'lovely', "n't", 'lovely', 'made', 'love', "n't", 'pretty', 'truly', 'angel', 'best', 'boy', 'happy', 'heaven', 'blessed', "n't", 'believe', 'god', 'done', 'given', 'life', 'one', "n't", 'lovely', 'made', 'love', "n't", 'lovely', 'life', 'love', 'life', 'aisha', 'meaning', 'name', 'londie', 'could', 'done', 'without', 'conceived', 'one', 'lovely', 'made', 'love']
    


```python
vocab = Counter(words)
print(vocab)

```

    Counter({"n't": 8, 'lovely': 6, 'love': 5, 'one': 4, 'made': 3, 'life': 3, 'done': 2, 'wonderful': 1, 'precious': 1, 'less': 1, 'minute': 1, 'old': 1, 'never': 1, 'thought': 1, 'making': 1, 'pretty': 1, 'truly': 1, 'angel': 1, 'best': 1, 'boy': 1, 'happy': 1, 'heaven': 1, 'blessed': 1, 'believe': 1, 'god': 1, 'given': 1, 'aisha': 1, 'meaning': 1, 'name': 1, 'londie': 1, 'could': 1, 'without': 1, 'conceived': 1})
    


```python
print(vocab['lovely'])
```

    6
    


```python
# ë¹ˆë„ìˆ˜ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ê¸°
vocab_sorted = sorted(vocab.items(), key = lambda x:x[1], reverse = True)
print(vocab_sorted)
```

    [("n't", 8), ('lovely', 6), ('love', 5), ('one', 4), ('made', 3), ('life', 3), ('done', 2), ('wonderful', 1), ('precious', 1), ('less', 1), ('minute', 1), ('old', 1), ('never', 1), ('thought', 1), ('making', 1), ('pretty', 1), ('truly', 1), ('angel', 1), ('best', 1), ('boy', 1), ('happy', 1), ('heaven', 1), ('blessed', 1), ('believe', 1), ('god', 1), ('given', 1), ('aisha', 1), ('meaning', 1), ('name', 1), ('londie', 1), ('could', 1), ('without', 1), ('conceived', 1)]
    


```python
# ë†’ì€ ë¹ˆë„ìˆ˜ë¥¼ ê°€ì§„ ë‹¨ì–´ì¼ìˆ˜ë¡ ë‚®ì€ ì •ìˆ˜ ì¸ë±ìŠ¤ë¥¼ ë¶€ì—¬
word2idx = {}

i = 0
for (word, frequency) in vocab_sorted :

  # ë¹ˆë„ìˆ˜
  if frequency > 1:
    i = i + 1
    word2idx[word] = i

print(word2idx)

```

    {"n't": 1, 'lovely': 2, 'love': 3, 'one': 4, 'made': 5, 'life': 6, 'done': 7}
    

ë‹¨ì–´ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ, ë¹ˆë„ìˆ˜ ìƒìœ„ top5ë§Œ ì‚¬ìš©í•˜ê³  ì‹¶ìœ¼ë©´?


```python
vocab_size = 5
words_frequency = [w for w, c in word2idx.items() if c >= vocab_size + 1] # ì¸ë±ìŠ¤ vocab_sizeë¥¼ ì´ˆê³¼í•˜ëŠ” ëª¨ë“  ë‹¨ì–´ì˜ ëª©ë¡ íšë“
for w in words_frequency:
  del word2idx[w]
print(word2idx)

```

    {"n't": 1, 'lovely': 2, 'love': 3, 'one': 4, 'made': 5}
    

ì‹¤ì œ í…ìŠ¤íŠ¸ë¥¼ ì •ìˆ˜ë¡œ í‘œí˜„í•˜ê¸°


```python
# OOVë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ UNK í† í° ì¶”ê°€
word2idx['UNK'] = 6
print(word2idx)
```

    {"n't": 1, 'lovely': 2, 'love': 3, 'one': 4, 'made': 5, 'UNK': 6}
    


```python
encoded = []
for s in sentences:
  temp = []
  for w in s:
    if w in word2idx:
      temp.append(word2idx[w])
    else:
      temp.append(word2idx['UNK'])
  encoded.append(temp)
print("ë³€í™˜ ì „ : {}".format(sentences[:5]))
print("ë³€í™˜ í›„ : {}".format(encoded[:5]))

```

    ë³€í™˜ ì „ : [["n't", 'lovely'], ["n't", 'wonderful'], ["n't", 'precious'], ['less', 'one', 'minute', 'old'], ['never', 'thought', 'love']]
    ë³€í™˜ í›„ : [[1, 2], [1, 6], [1, 6], [6, 4, 6, 6], [6, 6, 3]]
    

# Vocab & Integer Encodingì„ Tensorflowë¡œ


```python
print(sentences)
```

    [["n't", 'lovely'], ["n't", 'wonderful'], ["n't", 'precious'], ['less', 'one', 'minute', 'old'], ['never', 'thought', 'love'], ['making', 'one', 'lovely'], ["n't", 'lovely', 'made', 'love'], ["n't", 'pretty'], ['truly', 'angel', 'best'], ['boy', 'happy'], ['heaven', 'blessed'], ["n't", 'believe', 'god', 'done'], ['given', 'life', 'one'], ["n't", 'lovely', 'made', 'love'], ["n't", 'lovely'], ['life', 'love'], ['life', 'aisha'], ['meaning', 'name'], ['londie', 'could', 'done'], ['without', 'conceived', 'one'], ['lovely', 'made', 'love']]
    

keras.preprocessing.text.Tokenizer ì œê³µ

* fit_on_textsë¥¼ ì‚¬ìš©í•˜ë©´ ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¡œë¶€í„° ** ë‹¨ì–´ ë¹ˆë„ìˆ˜** ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ë‚®ì€ ì •ìˆ˜ ì¸ë±ìŠ¤ë¥¼ ë¶€ì—¬


```python
from tensorflow.keras.preprocessing.text import Tokenizer
```


```python
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences)

print(tokenizer.word_index)
```

    {"n't": 1, 'lovely': 2, 'love': 3, 'one': 4, 'made': 5, 'life': 6, 'done': 7, 'wonderful': 8, 'precious': 9, 'less': 10, 'minute': 11, 'old': 12, 'never': 13, 'thought': 14, 'making': 15, 'pretty': 16, 'truly': 17, 'angel': 18, 'best': 19, 'boy': 20, 'happy': 21, 'heaven': 22, 'blessed': 23, 'believe': 24, 'god': 25, 'given': 26, 'aisha': 27, 'meaning': 28, 'name': 29, 'londie': 30, 'could': 31, 'without': 32, 'conceived': 33}
    


```python
# ê° ë‹¨ì–´ì˜ ë¹ˆë„ìˆ˜ í™•ì¸
print(tokenizer.word_counts)
```

    OrderedDict([("n't", 8), ('lovely', 6), ('wonderful', 1), ('precious', 1), ('less', 1), ('one', 4), ('minute', 1), ('old', 1), ('never', 1), ('thought', 1), ('love', 5), ('making', 1), ('made', 3), ('pretty', 1), ('truly', 1), ('angel', 1), ('best', 1), ('boy', 1), ('happy', 1), ('heaven', 1), ('blessed', 1), ('believe', 1), ('god', 1), ('done', 2), ('given', 1), ('life', 3), ('aisha', 1), ('meaning', 1), ('name', 1), ('londie', 1), ('could', 1), ('without', 1), ('conceived', 1)])
    


```python
# ì •ìˆ˜ ì¸ì½”ë”© ìˆ˜í–‰
print(tokenizer.texts_to_sequences(sentences))
```

    [[1, 2], [1, 8], [1, 9], [10, 4, 11, 12], [13, 14, 3], [15, 4, 2], [1, 2, 5, 3], [1, 16], [17, 18, 19], [20, 21], [22, 23], [1, 24, 25, 7], [26, 6, 4], [1, 2, 5, 3], [1, 2], [6, 3], [6, 27], [28, 29], [30, 31, 7], [32, 33, 4], [2, 5, 3]]
    

ìƒìœ„ nê°œì˜ ë‹¨ì–´ë§Œ ì‚¬ìš©í•˜ê¸°



```python
vocab_size = 5
tokenizer = Tokenizer(num_words = vocab_size + 1) # ìƒìœ„ 5ê°œì˜ ë‹¨ì–´ë§Œ ì‚¬ìš©
tokenizer.fit_on_texts(sentences)
```


```python
print(tokenizer.word_index)
```

    {"n't": 1, 'lovely': 2, 'love': 3, 'one': 4, 'made': 5, 'life': 6, 'done': 7, 'wonderful': 8, 'precious': 9, 'less': 10, 'minute': 11, 'old': 12, 'never': 13, 'thought': 14, 'making': 15, 'pretty': 16, 'truly': 17, 'angel': 18, 'best': 19, 'boy': 20, 'happy': 21, 'heaven': 22, 'blessed': 23, 'believe': 24, 'god': 25, 'given': 26, 'aisha': 27, 'meaning': 28, 'name': 29, 'londie': 30, 'could': 31, 'without': 32, 'conceived': 33}
    


```python
print(tokenizer.texts_to_sequences(sentences))
```

    [[1, 2], [1], [1], [4], [3], [4, 2], [1, 2, 5, 3], [1], [], [], [], [1], [4], [1, 2, 5, 3], [1, 2], [3], [], [], [], [4], [2, 5, 3]]
    


```python
# OOV, PADDING ê°™ì´ ê³ ë ¤
tokenizer = Tokenizer(num_words = vocab_size + 2, oov_token = 'OOV')
tokenizer.fit_on_texts(sentences)
print(tokenizer.texts_to_sequences(sentences))
```

    [[2, 3], [2, 1], [2, 1], [1, 5, 1, 1], [1, 1, 4], [1, 5, 3], [2, 3, 6, 4], [2, 1], [1, 1, 1], [1, 1], [1, 1], [2, 1, 1, 1], [1, 1, 5], [2, 3, 6, 4], [2, 3], [1, 4], [1, 1], [1, 1], [1, 1, 1], [1, 1, 5], [3, 6, 4]]
    


```python
print("OOVì˜ ì¸ë±ìŠ¤ : {}".format(tokenizer.word_index['OOV']))
```

    OOVì˜ ì¸ë±ìŠ¤ : 1
    

# í•œêµ­ì–´ ë¬¸ì¥ í† í°í™” ë° ì •ìˆ˜ ì¸ì½”ë”© í•˜ê¸°


```python
!pip install konlpy
```

    Collecting konlpy
    [?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.4MB 1.2MB/s 
    [?25hCollecting JPype1>=0.7.0
    [?25l  Downloading https://files.pythonhosted.org/packages/fd/96/1030895dea70855a2e1078e3fe0d6a63dcb7c212309e07dc9ee39d33af54/JPype1-1.1.2-cp36-cp36m-manylinux2010_x86_64.whl (450kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 460kB 46.4MB/s 
    [?25hCollecting tweepy>=3.7.0
      Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl
    Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)
    Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)
    Collecting beautifulsoup4==4.6.0
    [?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 10.1MB/s 
    [?25hCollecting colorama
      Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl
    Requirement already satisfied: typing-extensions; python_version < "3.8" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)
    Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)
    Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)
    Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)
    Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)
    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)
    Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)
    Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == "socks" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)
    Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)
    Installing collected packages: JPype1, tweepy, beautifulsoup4, colorama, konlpy
      Found existing installation: tweepy 3.6.0
        Uninstalling tweepy-3.6.0:
          Successfully uninstalled tweepy-3.6.0
      Found existing installation: beautifulsoup4 4.6.3
        Uninstalling beautifulsoup4-4.6.3:
          Successfully uninstalled beautifulsoup4-4.6.3
    Successfully installed JPype1-1.1.2 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0
    


```python
!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git
%cd Mecab-ko-for-Google-Colab
!bash install_mecab-ko_on_colab190912.sh
```

    Cloning into 'Mecab-ko-for-Google-Colab'...
    remote: Enumerating objects: 72, done.[K
    remote: Counting objects: 100% (72/72), done.[K
    remote: Compressing objects: 100% (67/67), done.[K
    remote: Total 72 (delta 31), reused 20 (delta 5), pack-reused 0[K
    Unpacking objects: 100% (72/72), done.
    /content/Mecab-ko-for-Google-Colab
    Installing konlpy.....
    Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)
    Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)
    Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)
    Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)
    Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)
    Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.1.2)
    Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.4)
    Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)
    Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)
    Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)
    Requirement already satisfied: typing-extensions; python_version < "3.8" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)
    Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)
    Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)
    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)
    Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)
    Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == "socks" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)
    Done
    Installing mecab-0.996-ko-0.9.2.tar.gz.....
    Downloading mecab-0.996-ko-0.9.2.tar.gz.......
    from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
    --2020-11-12 00:17:01--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
    Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::22c3:9b0a, ...
    Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.
    HTTP request sent, awaiting response... 302 Found
    Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=3w8FXIAwcPaP%2F%2F%2F5jr2h%2FIM8LBg%3D&Expires=1605141645&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]
    --2020-11-12 00:17:02--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=3w8FXIAwcPaP%2F%2F%2F5jr2h%2FIM8LBg%3D&Expires=1605141645&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None
    Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.239.155
    Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.239.155|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 1414979 (1.3M) [application/x-tar]
    Saving to: â€˜mecab-0.996-ko-0.9.2.tar.gzâ€™
    
    mecab-0.996-ko-0.9. 100%[===================>]   1.35M  1.24MB/s    in 1.1s    
    
    2020-11-12 00:17:04 (1.24 MB/s) - â€˜mecab-0.996-ko-0.9.2.tar.gzâ€™ saved [1414979/1414979]
    
    Done
    Unpacking mecab-0.996-ko-0.9.2.tar.gz.......
    Done
    Change Directory to mecab-0.996-ko-0.9.2.......
    installing mecab-0.996-ko-0.9.2.tar.gz........
    configure
    make
    make check
    make install
    ldconfig
    Done
    Change Directory to /content
    Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......
    from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz
    --2020-11-12 00:18:31--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz
    Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22e9:9f55, 2406:da00:ff00::6b17:d1f5, ...
    Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.
    HTTP request sent, awaiting response... 302 Found
    Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=NuZ9RacuGLb8MxGlauLYwHCIc1Q%3D&Expires=1605141333&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]
    --2020-11-12 00:18:32--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=NuZ9RacuGLb8MxGlauLYwHCIc1Q%3D&Expires=1605141333&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None
    Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.100.59
    Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.100.59|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 49775061 (47M) [application/x-tar]
    Saving to: â€˜mecab-ko-dic-2.1.1-20180720.tar.gzâ€™
    
    mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  13.0MB/s    in 4.0s    
    
    2020-11-12 00:18:36 (11.9 MB/s) - â€˜mecab-ko-dic-2.1.1-20180720.tar.gzâ€™ saved [49775061/49775061]
    
    Done
    Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......
    Done
    Change Directory to mecab-ko-dic-2.1.1-20180720
    Done
    installing........
    configure
    make
    make install
    apt-get update
    apt-get upgrade
    apt install curl
    apt install git
    bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)
    Done
    Successfully Installed
    Now you can use Mecab
    from konlpy.tag import Mecab
    mecab = Mecab()
    ì‚¬ìš©ì ì‚¬ì „ ì¶”ê°€ ë°©ë²• : https://bit.ly/3k0ZH53
    


```python
import pandas as pd
import numpy as np
import urllib.request
from tensorflow.keras.preprocessing.text import Tokenizer
```


```python
urllib.request.urlretrieve("https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt", filename="ratings_test.txt")
```




    ('ratings_test.txt', <http.client.HTTPMessage at 0x7f422bb99e10>)




```python
train_data = pd.read_table("ratings_test.txt")
train_data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 50000 entries, 0 to 49999
    Data columns (total 3 columns):
     #   Column    Non-Null Count  Dtype 
    ---  ------    --------------  ----- 
     0   id        50000 non-null  int64 
     1   document  49997 non-null  object
     2   label     50000 non-null  int64 
    dtypes: int64(2), object(1)
    memory usage: 1.1+ MB
    


```python
train_data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>document</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6270596</td>
      <td>êµ³ ã…‹</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9274899</td>
      <td>GDNTOPCLASSINTHECLUB</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8544678</td>
      <td>ë­ì•¼ ì´ í‰ì ë“¤ì€.... ë‚˜ì˜ì§„ ì•Šì§€ë§Œ 10ì  ì§œë¦¬ëŠ” ë”ë”ìš± ì•„ë‹ˆì–ì•„</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6825595</td>
      <td>ì§€ë£¨í•˜ì§€ëŠ” ì•Šì€ë° ì™„ì „ ë§‰ì¥ì„... ëˆì£¼ê³  ë³´ê¸°ì—ëŠ”....</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6723715</td>
      <td>3Dë§Œ ì•„ë‹ˆì—ˆì–´ë„ ë³„ ë‹¤ì„¯ ê°œ ì¤¬ì„í…ë°.. ì™œ 3Dë¡œ ë‚˜ì™€ì„œ ì œ ì‹¬ê¸°ë¥¼ ë¶ˆí¸í•˜ê²Œ í•˜ì£ ??</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
from konlpy.tag import Mecab
from konlpy.tag import Okt # íŠ¸ìœ„í„°
okt = Okt()
mecab = Mecab()
train_data['document'] = train_data['document'].str.replace("[^ã„±-ã…ã…-ã…£ê°€-í£ ]","")
# í•œê¸€ê³¼ ê³µë°±ì„ ì œì™¸í•˜ê³  ëª¨ë‘ ì œê±°
train_data

```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>document</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6270596</td>
      <td>êµ³ ã…‹</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8544678</td>
      <td>ë­ì•¼ ì´ í‰ì ë“¤ì€ ë‚˜ì˜ì§„ ì•Šì§€ë§Œ ì  ì§œë¦¬ëŠ” ë”ë”ìš± ì•„ë‹ˆì–ì•„</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6825595</td>
      <td>ì§€ë£¨í•˜ì§€ëŠ” ì•Šì€ë° ì™„ì „ ë§‰ì¥ì„ ëˆì£¼ê³  ë³´ê¸°ì—ëŠ”</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6723715</td>
      <td>ë§Œ ì•„ë‹ˆì—ˆì–´ë„ ë³„ ë‹¤ì„¯ ê°œ ì¤¬ì„í…ë° ì™œ ë¡œ ë‚˜ì™€ì„œ ì œ ì‹¬ê¸°ë¥¼ ë¶ˆí¸í•˜ê²Œ í•˜ì£ </td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>7898805</td>
      <td>ìŒì•…ì´ ì£¼ê°€ ëœ ìµœê³ ì˜ ìŒì•…ì˜í™”</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>49995</th>
      <td>4608761</td>
      <td>ì˜¤ëœë§Œì— í‰ì  ë¡œê¸´í–ˆë„¤ã…‹ã…‹ í‚¹ì™•ì§± ìŒˆë½•í•œ ì˜í™”ë¥¼ ë§Œë‚¬ìŠµë‹ˆë‹¤ ê°•ë ¬í•˜ê²Œ ìœ¡ì¾Œí•¨</td>
      <td>1</td>
    </tr>
    <tr>
      <th>49996</th>
      <td>5308387</td>
      <td>ì˜ì§€ ë°•ì•½ë“¤ì´ë‚˜ í•˜ëŠ”ê±°ë‹¤ íƒˆì˜ì€ ì¼ë‹¨ ì£¼ì¸ê³µ ê¹€ëŒ€í¬ ë‹®ì•˜ê³  ì´ë“±ë³‘ ì°ë”°</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49997</th>
      <td>9072549</td>
      <td>ê·¸ë¦¼ë„ ì¢‹ê³  ì™„ì„±ë„ë„ ë†’ì•˜ì§€ë§Œ ë³´ëŠ” ë‚´ë‚´ ë¶ˆì•ˆí•˜ê²Œ ë§Œë“ ë‹¤</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49998</th>
      <td>5802125</td>
      <td>ì ˆëŒ€ ë´ì„œëŠ” ì•ˆ ë  ì˜í™” ì¬ë¯¸ë„ ì—†ê³  ê¸°ë¶„ë§Œ ì¡ì¹˜ê³  í•œ ì„¸íŠ¸ì¥ì—ì„œ ë‹¤ í•´ë¨¹ë„¤</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49999</th>
      <td>6070594</td>
      <td>ë§ˆë¬´ë¦¬ëŠ” ë˜ ì™œì´ë˜</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>48417 rows Ã— 3 columns</p>
</div>




```python
train_data['document'].nunique()
```




    (48418, 2)




```python
train_data.loc[train_data.document.isnull()]
train_data = train_data.dropna() # Null ê°’ì´ ì¡´ì¬í•˜ëŠ” í–‰ ì œê±°
train_data['document'].replace('', np.nan, inplace=True)
print(train_data.isnull().sum())
train_data.head(10)
```

    id          0
    document    0
    label       0
    dtype: int64
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>document</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6270596</td>
      <td>êµ³ ã…‹</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8544678</td>
      <td>ë­ì•¼ ì´ í‰ì ë“¤ì€ ë‚˜ì˜ì§„ ì•Šì§€ë§Œ ì  ì§œë¦¬ëŠ” ë”ë”ìš± ì•„ë‹ˆì–ì•„</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6825595</td>
      <td>ì§€ë£¨í•˜ì§€ëŠ” ì•Šì€ë° ì™„ì „ ë§‰ì¥ì„ ëˆì£¼ê³  ë³´ê¸°ì—ëŠ”</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6723715</td>
      <td>ë§Œ ì•„ë‹ˆì—ˆì–´ë„ ë³„ ë‹¤ì„¯ ê°œ ì¤¬ì„í…ë° ì™œ ë¡œ ë‚˜ì™€ì„œ ì œ ì‹¬ê¸°ë¥¼ ë¶ˆí¸í•˜ê²Œ í•˜ì£ </td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>7898805</td>
      <td>ìŒì•…ì´ ì£¼ê°€ ëœ ìµœê³ ì˜ ìŒì•…ì˜í™”</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>6315043</td>
      <td>ì§„ì •í•œ ì“°ë ˆê¸°</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>6097171</td>
      <td>ë§ˆì¹˜ ë¯¸êµ­ì• ë‹ˆì—ì„œ íŠ€ì–´ë‚˜ì˜¨ë“¯í•œ ì°½ì˜ë ¥ì—†ëŠ” ë¡œë´‡ë””ìì¸ë¶€í„°ê°€ê³ ê°œë¥¼ ì –ê²Œí•œë‹¤</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>8932678</td>
      <td>ê°ˆìˆ˜ë¡ ê°œíŒë˜ê°€ëŠ” ì¤‘êµ­ì˜í™” ìœ ì¹˜í•˜ê³  ë‚´ìš©ì—†ìŒ í¼ì¡ë‹¤ ëë‚¨ ë§ë„ì•ˆë˜ëŠ” ë¬´ê¸°ì— ìœ ì¹˜í•œë‚¨...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>6242223</td>
      <td>ì´ë³„ì˜ ì•„í””ë’¤ì— ì°¾ì•„ì˜¤ëŠ” ìƒˆë¡œìš´ ì¸ì—°ì˜ ê¸°ì¨  ëª¨ë“  ì‚¬ëŒì´ ê·¸ë ‡ì§€ëŠ” ì•Šë„¤</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10</th>
      <td>7462111</td>
      <td>ê´œì°®ë„¤ìš”ì˜¤ëœë§Œí¬ì¼“ëª¬ìŠ¤í„°ì¼ë°Œì–´ìš”</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
from konlpy.tag import Okt # íŠ¸ìœ„í„°
okt = Okt()
```


```python
stopwords = ['ì˜','ê°€','ì´','ì€','ë“¤','ëŠ”','ì¢€','ì˜','ê±','ê³¼','ë„','ë¥¼','ìœ¼ë¡œ','ì','ì—','ì™€','í•œ','í•˜ë‹¤']
train2 = []
for sentence in train_data['document']:
    temp_X = []
    temp_X = okt.morphs(sentence, stem=True) # í† í°í™”
    temp_X = [word for word in temp_X if not word in stopwords] # ë¶ˆìš©ì–´ ì œê±°
    train2.append(temp_X)

```


```python
train2
```


```python
tokenizer = Tokenizer()
tokenizer.fit_on_texts(train2)

```


```python
print(tokenizer.word_index)
```


```python
# ê° ë‹¨ì–´ì˜ ë¹ˆë„ìˆ˜ í™•ì¸
print(tokenizer.word_counts)
```


```python
# ì •ìˆ˜ ì¸ì½”ë”© ìˆ˜í–‰
print(tokenizer.texts_to_sequences(train2))
```


    Output hidden; open in https://colab.research.google.com to view.



```python
vocab_size = 5
tokenizer = Tokenizer(num_words = vocab_size + 1) # ìƒìœ„ 5ê°œì˜ ë‹¨ì–´ë§Œ ì‚¬ìš©
tokenizer.fit_on_texts(train2)
```


```python
print(tokenizer.texts_to_sequences(train2))
```


```python
# OOV, PADDING ê°™ì´ ê³ ë ¤
tokenizer = Tokenizer(num_words = vocab_size + 2, oov_token = 'OOV')
tokenizer.fit_on_texts(train2)
print(tokenizer.texts_to_sequences(train2))
```

# TF-IDF
* TF : Term Frequency
* IDF : Inverse Document Frequency


```python
# në²ˆì§¸ ë¬¸ì„œ(document)ì—ì„œ ë‹¨ì–´(term)ê°€ ë“±ì¥í•œ íšŸìˆ˜
def term_frequency(term, document):
  return document.count(term)

  # ë‹¨ì–´(term)ê°€ ë¬¸ì„œ'ë“¤' (documents)ì—ì„œ ë“±ì¥í•œ ë¬¸ì„œì˜ ìˆ˜
def document_frequency(term, documents):
  term_count = 0
  
  for document in documents:
    term_count += term in document
  return term_count
def inverse_document_frequency(term, documents):
  from math import log
  
  N = len(documents)
  df = document_frequency(term, documents)

  return log(N / (df + 1))

# idxë²ˆ ë¬¸ì„œì— termì— ëŒ€í•œ tf-idfë¥¼ êµ¬í•´ì•¼ í•œë‹¤.
def tf_idf(term, documents, idx):
  document = documents[idx]
  return term_frequency(term, document) * inverse_document_frequency(term,documents)
```


```python
sample = "hello bye bye"
sample.count("bye")
term_frequency("bye", sample)
```




    2




```python
docs = [
  'ë™í•´ ë¬¼ê³¼ ë°±ë‘ì‚°ì´ ë§ˆë¥´ê³  ë‹³ë„ë¡ í•˜ëŠë‹˜ì´ ë³´ìš°í•˜ì‚¬ ìš°ë¦¬ë‚˜ë¼ ë§Œì„¸. ë¬´ê¶í™” ì‚¼ì²œë¦¬ í™”ë ¤ ê°•ì‚° ëŒ€í•œ ì‚¬ëŒ, ëŒ€í•œìœ¼ë¡œ ê¸¸ì´ ë³´ì „í•˜ì„¸. ë™í•´ ê°€ê³  ì‹¶ë‹¤',
  'ë‚¨ì‚° ìœ„ì— ì € ì†Œë‚˜ë¬´, ì² ê°‘ì„ ë‘ë¥¸ ë“¯ ë°”ëŒ ì„œë¦¬ ë¶ˆë³€í•¨ì€ ìš°ë¦¬ ê¸°ìƒì¼ì„¸. ë¬´ê¶í™” ì‚¼ì²œë¦¬ í™”ë ¤ ê°•ì‚° ëŒ€í•œ ì‚¬ëŒ, ëŒ€í•œìœ¼ë¡œ ê¸¸ì´ ë³´ì „í•˜ì„¸. ì†Œë‚˜ë¬´ ì´ì˜ë‹¤',
  'ê°€ì„ í•˜ëŠ˜ ê³µí™œí•œë° ë†’ê³  êµ¬ë¦„ ì—†ì´ ë°ì€ ë‹¬ì€ ìš°ë¦¬ ê°€ìŠ´ ì¼í¸ë‹¨ì‹¬ì¼ì„¸. ë¬´ê¶í™” ì‚¼ì²œë¦¬ í™”ë ¤ ê°•ì‚° ëŒ€í•œ ì‚¬ëŒ, ëŒ€í•œìœ¼ë¡œ ê¸¸ì´ ë³´ì „í•˜ì„¸. ê°€ì„ í•˜ëŠ˜ ë³´ê³  ì‹¶ë‹¤.',
  'ì´ ê¸°ìƒê³¼ ì´ ë§ˆìŒìœ¼ë¡œ ì¶©ì„±ì„ ë‹¤í•˜ì—¬ ê´´ë¡œìš°ë‚˜ ì¦ê±°ìš°ë‚˜ ë‚˜ë¼ ì‚¬ë‘í•˜ì„¸. ë¬´ê¶í™” ì‚¼ì²œë¦¬ í™”ë ¤ ê°•ì‚° ëŒ€í•œ ì‚¬ëŒ, ëŒ€í•œìœ¼ë¡œ ê¸¸ì´ ë³´ì „í•˜ì„¸. ë‚˜ë¼ë¥¼ ì‚¬ë‘í•˜ì'
]
```


```python
from konlpy.tag import Mecab
mecab = Mecab()

vocab = list(set(w for doc in docs for w in mecab.nouns(doc)))
vocab.sort()
```


```python
print(vocab)
```

    ['ê°€ìŠ´', 'ê°€ì„', 'ê°•ì‚°', 'êµ¬ë¦„', 'ê¸°ìƒ', 'ê¸¸', 'ë‚˜ë¼', 'ë‚¨ì‚°', 'ë‹¬', 'ëŒ€í•œ', 'ë°', 'ë™í•´', 'ë“¯', 'ë§ˆìŒ', 'ë§Œì„¸', 'ë¬´ê¶í™”', 'ë¬¼', 'ë°”ëŒ', 'ë°±ë‘ì‚°', 'ë³´ìš°', 'ë³´ì „', 'ë¶ˆë³€', 'ì‚¬ëŒ', 'ì‚¬ë‘', 'ì‚¼ì²œë¦¬', 'ì„œë¦¬', 'ì†Œë‚˜ë¬´', 'ìš°ë¦¬', 'ìœ„', 'ì¼í¸ë‹¨ì‹¬', 'ì² ê°‘', 'ì¶©ì„±', 'í•˜ëŠë‹˜', 'í•˜ëŠ˜', 'í™”ë ¤']
    


```python
# DTM(TF) ë§Œë“¤ê¸°
import pandas as pd

result = [] # ë°ì´í„° í”„ë ˆì„ í–‰ ë°ì´í„°ë¥¼ ë‹´ì•„ë‚¼ ë°°ì—´

for i in range(len(docs)):
  result.append([])
  d = docs[i] # ë¬¸ì„œ

  for j in range(len(vocab)):
    t = vocab[j]
    result[-1].append(term_frequency(t, d))

tf_ = pd.DataFrame(result, columns = vocab)
tf_


```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ê°€ìŠ´</th>
      <th>ê°€ì„</th>
      <th>ê°•ì‚°</th>
      <th>êµ¬ë¦„</th>
      <th>ê¸°ìƒ</th>
      <th>ê¸¸</th>
      <th>ë‚˜ë¼</th>
      <th>ë‚¨ì‚°</th>
      <th>ë‹¬</th>
      <th>ëŒ€í•œ</th>
      <th>ë°</th>
      <th>ë™í•´</th>
      <th>ë“¯</th>
      <th>ë§ˆìŒ</th>
      <th>ë§Œì„¸</th>
      <th>ë¬´ê¶í™”</th>
      <th>ë¬¼</th>
      <th>ë°”ëŒ</th>
      <th>ë°±ë‘ì‚°</th>
      <th>ë³´ìš°</th>
      <th>ë³´ì „</th>
      <th>ë¶ˆë³€</th>
      <th>ì‚¬ëŒ</th>
      <th>ì‚¬ë‘</th>
      <th>ì‚¼ì²œë¦¬</th>
      <th>ì„œë¦¬</th>
      <th>ì†Œë‚˜ë¬´</th>
      <th>ìš°ë¦¬</th>
      <th>ìœ„</th>
      <th>ì¼í¸ë‹¨ì‹¬</th>
      <th>ì² ê°‘</th>
      <th>ì¶©ì„±</th>
      <th>í•˜ëŠë‹˜</th>
      <th>í•˜ëŠ˜</th>
      <th>í™”ë ¤</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
# TF-IDF ë°ì´í„° í”„ë ˆì„ ë§Œë“¤ê¸°
for j in range(len(vocab)):
    t = vocab[j]
    result[-1].append(term_frequency(t, docs))

idf_ = pd.DataFrame(result, columns = ["IDF"])
idf_

```


    ---------------------------------------------------------------------------

    AssertionError                            Traceback (most recent call last)

    /usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py in _list_to_arrays(data, columns, coerce_float, dtype)
        563     try:
    --> 564         columns = _validate_or_indexify_columns(content, columns)
        565         result = _convert_object_array(content, dtype=dtype, coerce_float=coerce_float)
    

    /usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py in _validate_or_indexify_columns(content, columns)
        688             raise AssertionError(
    --> 689                 f"{len(columns)} columns passed, passed data had "
        690                 f"{len(content)} columns"
    

    AssertionError: 1 columns passed, passed data had 70 columns

    
    The above exception was the direct cause of the following exception:
    

    ValueError                                Traceback (most recent call last)

    <ipython-input-22-3852f6f4bd4d> in <module>()
          4     result[-1].append(term_frequency(t, docs))
          5 
    ----> 6 idf_ = pd.DataFrame(result, columns = ["IDF"])
          7 idf_
    

    /usr/local/lib/python3.6/dist-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy)
        507                     if is_named_tuple(data[0]) and columns is None:
        508                         columns = data[0]._fields
    --> 509                     arrays, columns = to_arrays(data, columns, dtype=dtype)
        510                     columns = ensure_index(columns)
        511 
    

    /usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py in to_arrays(data, columns, coerce_float, dtype)
        522         return [], []  # columns if columns is not None else []
        523     if isinstance(data[0], (list, tuple)):
    --> 524         return _list_to_arrays(data, columns, coerce_float=coerce_float, dtype=dtype)
        525     elif isinstance(data[0], abc.Mapping):
        526         return _list_of_dict_to_arrays(
    

    /usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py in _list_to_arrays(data, columns, coerce_float, dtype)
        565         result = _convert_object_array(content, dtype=dtype, coerce_float=coerce_float)
        566     except AssertionError as e:
    --> 567         raise ValueError(e) from e
        568     return result, columns
        569 
    

    ValueError: 1 columns passed, passed data had 70 columns


# Tensorflowë¡œ BOW êµ¬í˜„í•˜ê¸°


```python
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
```


```python
t = Tokenizer()
t.fit_on_texts(docs)
print(t.word_index)
```

    {'ë¬´ê¶í™”': 1, 'ì‚¼ì²œë¦¬': 2, 'í™”ë ¤': 3, 'ê°•ì‚°': 4, 'ëŒ€í•œ': 5, 'ì‚¬ëŒ': 6, 'ëŒ€í•œìœ¼ë¡œ': 7, 'ê¸¸ì´': 8, 'ë³´ì „í•˜ì„¸': 9, 'ë™í•´': 10, 'ì‹¶ë‹¤': 11, 'ì†Œë‚˜ë¬´': 12, 'ìš°ë¦¬': 13, 'ê°€ì„': 14, 'í•˜ëŠ˜': 15, 'ì´': 16, 'ë¬¼ê³¼': 17, 'ë°±ë‘ì‚°ì´': 18, 'ë§ˆë¥´ê³ ': 19, 'ë‹³ë„ë¡': 20, 'í•˜ëŠë‹˜ì´': 21, 'ë³´ìš°í•˜ì‚¬': 22, 'ìš°ë¦¬ë‚˜ë¼': 23, 'ë§Œì„¸': 24, 'ê°€ê³ ': 25, 'ë‚¨ì‚°': 26, 'ìœ„ì—': 27, 'ì €': 28, 'ì² ê°‘ì„': 29, 'ë‘ë¥¸': 30, 'ë“¯': 31, 'ë°”ëŒ': 32, 'ì„œë¦¬': 33, 'ë¶ˆë³€í•¨ì€': 34, 'ê¸°ìƒì¼ì„¸': 35, 'ì´ì˜ë‹¤': 36, 'ê³µí™œí•œë°': 37, 'ë†’ê³ ': 38, 'êµ¬ë¦„': 39, 'ì—†ì´': 40, 'ë°ì€': 41, 'ë‹¬ì€': 42, 'ê°€ìŠ´': 43, 'ì¼í¸ë‹¨ì‹¬ì¼ì„¸': 44, 'ë³´ê³ ': 45, 'ê¸°ìƒê³¼': 46, 'ë§ˆìŒìœ¼ë¡œ': 47, 'ì¶©ì„±ì„': 48, 'ë‹¤í•˜ì—¬': 49, 'ê´´ë¡œìš°ë‚˜': 50, 'ì¦ê±°ìš°ë‚˜': 51, 'ë‚˜ë¼': 52, 'ì‚¬ë‘í•˜ì„¸': 53, 'ë‚˜ë¼ë¥¼': 54, 'ì‚¬ë‘í•˜ì': 55}
    


```python
print(t.texts_to_matrix(docs, mode = 'count')) # DTM
```

    [[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.
      1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
      0. 0. 0. 0. 0. 0. 0. 0.]
     [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
      0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
      0. 0. 0. 0. 0. 0. 0. 0.]
     [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0.
      0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.
      0. 0. 0. 0. 0. 0. 0. 0.]
     [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0.
      0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.
      1. 1. 1. 1. 1. 1. 1. 1.]]
    


```python
print(t.texts_to_matrix(docs, mode = 'tfidf').round(2))
```

    [[0.   0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 1.86 0.85 0.   0.
      0.   0.   0.   1.1  1.1  1.1  1.1  1.1  1.1  1.1  1.1  1.1  0.   0.
      0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
      0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
     [0.   0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.   0.   1.86 0.85
      0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.1  1.1
      1.1  1.1  1.1  1.1  1.1  1.1  1.1  1.1  1.1  0.   0.   0.   0.   0.
      0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
     [0.   0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.   0.85 0.   0.85
      1.86 1.86 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
      0.   0.   0.   0.   0.   0.   0.   0.   0.   1.1  1.1  1.1  1.1  1.1
      1.1  1.1  1.1  1.1  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
     [0.   0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.   0.   0.   0.
      0.   0.   1.86 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
      0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
      0.   0.   0.   0.   1.1  1.1  1.1  1.1  1.1  1.1  1.1  1.1  1.1  1.1 ]]
    


```python
print(t.texts_to_matrix(docs, mode = 'freq').round(2))
```

    [[0.   0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.1  0.05 0.   0.
      0.   0.   0.   0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.   0.
      0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
      0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
     [0.   0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.   0.   0.09 0.04
      0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.04 0.04
      0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.   0.   0.   0.   0.
      0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
     [0.   0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.   0.04 0.   0.04
      0.08 0.08 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
      0.   0.   0.   0.   0.   0.   0.   0.   0.   0.04 0.04 0.04 0.04 0.04
      0.04 0.04 0.04 0.04 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
     [0.   0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.   0.   0.   0.
      0.   0.   0.1  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
      0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
      0.   0.   0.   0.   0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05]]
    


```python
print(t.texts_to_matrix(docs, mode = 'binary').round(2))
```

    [[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.
      1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
      0. 0. 0. 0. 0. 0. 0. 0.]
     [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
      0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
      0. 0. 0. 0. 0. 0. 0. 0.]
     [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.
      0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.
      0. 0. 0. 0. 0. 0. 0. 0.]
     [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
      0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.
      1. 1. 1. 1. 1. 1. 1. 1.]]
    
