## 2021-07-01
```python
import tensorflow as tf
from tensorflow.keras import datasets

import matplotlib.pyplot as plt
%matplotlib inline
```


```python
(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()
```


```python
image = X_train[0]
```


```python
# 뽑아온 이미지 확인
plt.imshow(image, 'gray')
plt.show()
```


    
![output_3_0](https://user-images.githubusercontent.com/69663368/124225006-b02c9100-db41-11eb-8ff8-c9187874e290.png)
    



```python
# 실제 CNN 레이어에 집어 넣기 위해서는 데이터가 4차원이 되어야 한다.
# (배치, 세로, 가로 ,채널)

image = image[tf.newaxis, ..., tf.newaxis]
image.shape
```




    (1, 28, 28, 1)



# Conv2D 레이어 사용하기
* filters : 필터의 개수
* kernel_size : 필터의 크기
* strides : 몇 개의 픽셀을 스킵 하면서 필터가 훑게 할지
* padding : 0으로 쌓여진 패딩을 만들 것 인지에 대한 설정
 - VALID : 패딩을 만들지 않기
 - SAME : 패딩 만들기
* activation : 활성화 함수 지정. 지정하지 않고 따로 레이어로 추가할 수 도있음


```python
tf.keras.layers.Conv2D(filters = 3, kernel_size= (3, 3), # 필터가 3개, 필터의 크기는 3 X 3
                       strides = (1, 1), # 필터가 가로로 1px, 세로로 1px 이동한다.
                       padding = 'SAME', # 패딩 적용하기
                       activation = 'relu' # 활성화함수는 ReLU 사용
                       )
```




    <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff471df6278>




```python
# 필터의 가로, 세로 크기 및 스트라이드의 가로 세로를 똑같이 하려면 튜플을 사용할 필요가 없다.
tf.keras.layers.Conv2D(filters  = 3, kernel_size = 3, strides = 1, padding = 'SAME', activation = 'relu')
```




    <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff43db22e48>



# Convolution 레이어 시각화 하기


```python
# image를 tensorflow 배열로 만들기
image = tf.cast(image, dtype = tf.float32)
image.dtype
```




    tf.float32




```python
layer = tf.keras.layers.Conv2D(filters = 5, kernel_size = 3, strides = 1, padding = 'SAME')
```


```python
output = layer(image)
output.shape
```




    TensorShape([1, 28, 28, 5])




```python
_, axes = plt.subplots(nrows = 1, ncols =  6, figsize = (20, 10))

axes[0].imshow(image[0, ..., 0], cmap = 'gray')
axes[0].set_title("Original Image")

for idx, ax in enumerate(axes[1:]):
  ax.set_title("Output : {}".format(idx + 1))
  ax.imshow(output[0, ..., idx], cmap = 'gray')

plt.show()


```


    
![png](output_12_0.png)
    


# Filter 시각화 하기
CNN의 Filter값을 확인한다는 뜻은 가중치를 확인하겠다는 뜻이 된다


```python
# keras 의 모든 계산가능한 레이어는 각 레이어의 매개변수를 리턴할 수 있다.
# - get_weights() 사용
# Conv2D 레이어의 필터의 모양 : (필터세로, 필터가로, 채널수, 필터갯수)
weights = layer.get_weights()
```


```python
weights[0].shape, weights[1].shape
```




    ((3, 3, 1, 5), (5,))



# 필터 시각화 하기


```python
_, axes = plt.subplots(nrows = 1, ncols = 5, figsize = (20, 10))

for idx, ax in enumerate(axes):
  ax.set_title("filter {}".format(idx + 1))
  ax.imshow(weights[0][:, :, 0, idx], cmap = 'gray')
plt.show()
```


    
![png](output_17_0.png)
    


# ReLU 시각화 하기


```python
import numpy as np
np.min(output), np.max(output)
```




    (-270.47116, 200.2678)




```python
act_layer = tf.keras.layers.ReLU()
act_output = act_layer(output) # 합성곱의 결과가 활성화 레이어로 들어감
act_output.shape
```




    TensorShape([1, 28, 28, 5])




```python
_, axes = plt.subplots(nrows = 1, ncols =  6, figsize = (20, 10))

axes[0].imshow(image[0, ..., 0], cmap = 'gray')
axes[0].set_title("Original Image")

for idx, ax in enumerate(axes[1:]):
  ax.set_title("ReLU Output : {}".format(idx + 1))
  ax.imshow(act_output[0, ..., idx], cmap = 'gray')

plt.show()


```


    
![png](output_21_0.png)
    


# MaxPooling 레이어 확인하기


```python
pool_layer = tf.keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2), padding = 'SAME')
pool_output = pool_layer(act_output)

pool_output.shape
```




    TensorShape([1, 14, 14, 5])




```python
_, axes = plt.subplots(nrows = 1, ncols =  6, figsize = (20, 10))

axes[0].imshow(image[0, ..., 0], cmap = 'gray')
axes[0].set_title("Original Image")

for idx, ax in enumerate(axes[1:]):
  ax.set_title("MaxPool Output : {}".format(idx + 1))
  ax.imshow(pool_output[0, ..., idx], cmap = 'gray')

plt.show()


```


    
![png](output_24_0.png)
    


# Flatten 레이어 확인하기
- MaxPool2D 까지는 특징 추출 과정이다.
  - 예측을 위한 과정이 아닌, 데이터에 대한 특징만 추출함
- 예측을 하기 위해서는 Fully Connected Layer가 필요함
  - Dense 레이어 사용

- Fully Connected Layer를 사용하기 위해서는 데이터가 평탄화 되어 있어야 함.


```python
flatten_layer = tf.keras.layers.Flatten()
flatten_output = flatten_layer(pool_output)

flatten_output.shape
```




    TensorShape([1, 980])




```python
pool_output.shape
```




    TensorShape([1, 14, 14, 5])



# Dense 레이어 확인하기
 - 계산 과정을 위한 Dense 레이어 - Fully Connected 레이어 라고도 한다.



```python
# 유닛이 32개인 Dense Layer ( Affine 레이어 또는 Fully Connected Layer)
dense_layer = tf.keras.layers.Dense(32, activation = 'relu')
dense_output = dense_layer(flatten_output)

dense_output.shape
```




    TensorShape([1, 32])




```python
# 출력층 꾸미기
# 출력 클래스의 개수, 출력 함수가 필요해요
dense_layer2 = tf.keras.layers.Dense(10, activation = 'relu')
dense_output2 = dense_layer2(dense_output)

dense_output2.shape
```




    TensorShape([1, 10])




```python
# Feature Extraction을 위한 레이어
from tensorflow.keras.layers import Input, Conv2D, Activation, MaxPool2D

# Classfication을 위한 레이어
from tensorflow.keras.layers import Dense, Dropout, Flatten
```


```python
# 1. 입력 데이터의 형상( 배치 사이즈 제외 )
input_shape = (28, 28, 1)

# 2. 분류할 클래스의 개수
num_classes = 10
```


```python
# 원본 데이터를 입력받는 레이어
inputs = Input(shape = input_shape)

# Feature Extraction - Convolution 레이어
net = Conv2D(32, 3, padding ='SAME')(inputs)
net = Activation('relu')(net)
net = Conv2D(32, 3, padding='SAME')(net)
net = Activation('relu')(net)
net = MaxPool2D((2, 2))(net)
net = Dropout(0.25)(net)

net = Conv2D(64, 3, padding='SAME')(net)
net = Activation('relu')(net)
net = Conv2D(64, 3, padding='SAME')(net)
net = Activation('relu')(net)
net = MaxPool2D((2, 2))(net)
net = Dropout(0.25)(net)

# Fully Conneted 구성하기
net = Flatten()(net)
net = Dense(512)(net)
net = Activation('relu')(net)
net = Dropout(0.25)(net)

# 출력층 구성하기
net = Dense(num_classes)(net)
net = Activation('softmax')(net)

# 계산 그래프 그리기
model = tf.keras.Model(inputs = inputs, outputs = net, name = 'CNN')


```


```python
model.summary()
```

    Model: "CNN"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_1 (InputLayer)         [(None, 28, 28, 1)]       0         
    _________________________________________________________________
    conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       
    _________________________________________________________________
    activation (Activation)      (None, 28, 28, 32)        0         
    _________________________________________________________________
    conv2d_4 (Conv2D)            (None, 28, 28, 32)        9248      
    _________________________________________________________________
    activation_1 (Activation)    (None, 28, 28, 32)        0         
    _________________________________________________________________
    max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         
    _________________________________________________________________
    dropout (Dropout)            (None, 14, 14, 32)        0         
    _________________________________________________________________
    conv2d_5 (Conv2D)            (None, 14, 14, 64)        18496     
    _________________________________________________________________
    activation_2 (Activation)    (None, 14, 14, 64)        0         
    _________________________________________________________________
    conv2d_6 (Conv2D)            (None, 14, 14, 64)        36928     
    _________________________________________________________________
    activation_3 (Activation)    (None, 14, 14, 64)        0         
    _________________________________________________________________
    max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         
    _________________________________________________________________
    dropout_1 (Dropout)          (None, 7, 7, 64)          0         
    _________________________________________________________________
    flatten_1 (Flatten)          (None, 3136)              0         
    _________________________________________________________________
    dense_2 (Dense)              (None, 512)               1606144   
    _________________________________________________________________
    activation_4 (Activation)    (None, 512)               0         
    _________________________________________________________________
    dropout_2 (Dropout)          (None, 512)               0         
    _________________________________________________________________
    dense_3 (Dense)              (None, 10)                5130      
    _________________________________________________________________
    activation_5 (Activation)    (None, 10)                0         
    =================================================================
    Total params: 1,676,266
    Trainable params: 1,676,266
    Non-trainable params: 0
    _________________________________________________________________
    

# 최적화 선정하기
- Loss Function ( 손실 함수 ) - MSE, CEE를 쓸지 등등..
- Optimization ( 최적화 함수) - SGD, ADAM, RMSProps를 쓸지..
- Metrics ( 테스트 세트에 대한 평가 기준)

## Loss Function 선정 기준
* Binary Classification
* Categorical Classification

1. 이진 분류 시에는 binary_crossentropy
2. 다중 분류 시에는 categorical_crossentropy

### Categorical CrossEntropy의 종류
* Label이 0, 1, 2같은 형태면
  - sparse categorical crossentropy
* Label이 OneHotEncoding 되어 있는 경우
 - categorical crossentropy


```python
# Loss 선정을 위해 y_train 확인
y_train[:3]
```




    array([5, 0, 4], dtype=uint8)



sparse_categorical_crossentropy 사용하자



```python
loss_func = tf.keras.losses.sparse_categorical_crossentropy
loss_func
```




    <function tensorflow.python.keras.losses.sparse_categorical_crossentropy>




```python
# 레이블이 OHE 되어 있으면 쓰자
tf.keras.losses.categorical_crossentropy
```




    <function tensorflow.python.keras.losses.categorical_crossentropy>




```python
# 이진 분류 시에 쓰자
tf.keras.losses.binary_crossentropy
```




    <function tensorflow.python.keras.losses.binary_crossentropy>



# Metrics
  * 테스트 세트의 평가 방식( evulate )


```python
metrics = ['accuracy'] # ['acc'], tf.keras.metrics.Accuracy() 둘이 같은 방식이다.
```

# Optimzer 선정하기
* sgd - tf.keras.optimizers.SGD()
* rmsprop - tf.keras.optimizers.RMSprop()
* adam - tf.keras.optimizers.Adam()


```python
optm = tf.keras.optimizers.Adam()
```

# 모델 컴파일
  * 모델 만들기 과정


```python
model.compile(optimizer = optm, loss = loss_func, metrics = metrics)
```


```python
X_train = X_train [..., tf.newaxis]
X_test = X_test[..., tf.newaxis]
```


```python
X_train.shape, X_test.shape
```




    ((60000, 28, 28, 1), (10000, 28, 28, 1))




```python
# 정규화 작업 ( 스케일링 처리 )
X_train = X_train / 255.0
X_test = X_test / 255.0

np.min(X_train), np.max(X_train)
```




    (0.0, 1.0)



# 학습용 하이퍼 파라미터 설정
* num_epochs
* batch_size


```python
num_epochs = 10
batch_size = 32
```


```python
model.fit(
    X_train,
    y_train,
    batch_size = batch_size,
    epochs = num_epochs,
    shuffle = True
)
```

    Epoch 1/10
    1875/1875 [==============================] - 7s 4ms/step - loss: 0.1341 - accuracy: 0.9578
    Epoch 2/10
    1875/1875 [==============================] - 6s 3ms/step - loss: 0.0497 - accuracy: 0.9846
    Epoch 3/10
    1875/1875 [==============================] - 7s 3ms/step - loss: 0.0374 - accuracy: 0.9888
    Epoch 4/10
    1875/1875 [==============================] - 7s 3ms/step - loss: 0.0307 - accuracy: 0.9906
    Epoch 5/10
    1875/1875 [==============================] - 6s 3ms/step - loss: 0.0270 - accuracy: 0.9911
    Epoch 6/10
    1875/1875 [==============================] - 7s 3ms/step - loss: 0.0231 - accuracy: 0.9931
    Epoch 7/10
    1875/1875 [==============================] - 7s 3ms/step - loss: 0.0216 - accuracy: 0.9932
    Epoch 8/10
    1875/1875 [==============================] - 7s 4ms/step - loss: 0.0179 - accuracy: 0.9944
    Epoch 9/10
    1875/1875 [==============================] - 7s 4ms/step - loss: 0.0175 - accuracy: 0.9947
    Epoch 10/10
    1875/1875 [==============================] - 7s 4ms/step - loss: 0.0165 - accuracy: 0.9948
    




    <tensorflow.python.keras.callbacks.History at 0x7ff3d97d3fd0>




```python
test_img = X_test[0, :, :, 0]
plt.imshow(test_img, 'gray')
plt.show()
```


    
![png](output_55_0.png)
    



```python
test_img.shape
```




    (28, 28)




```python
test_img = test_img[tf.newaxis, ..., tf.newaxis]
test_img.shape
```




    (1, 28, 28, 1)




```python
prediction = model.predict(test_img)
np.argmax(prediction)
```




    7




```python
y_test[0]
```




    7




```python
model.predict(test_img)
```




    array([[1.6723150e-13, 4.8066431e-09, 7.0969558e-10, 5.2104952e-11,
            1.3330175e-11, 1.8537195e-13, 8.1659310e-17, 1.0000000e+00,
            3.7881230e-12, 1.7300201e-09]], dtype=float32)




```python

```
